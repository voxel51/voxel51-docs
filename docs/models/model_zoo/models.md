# Built-In Zoo Models [Â¶](\#built-in-zoo-models "Permalink to this headline")

This page lists all of the natively available models in the FiftyOne Model Zoo.

Check out the [API reference](api.md#model-zoo-api) for complete instructions
for using the Model Zoo.

* * *

#### alexnet-imagenet-torch

AlexNet model architecture from "One weird trick for parallelizing convolutional neural networks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Alexnet

#### centernet-hg104-1024-coco-tf2

CenterNet model from "Objects as Points" with the Hourglass-104 backbone trained on COCO resized to 1024x1024

Detection,Coco,TensorFlow-2,Centernet

#### centernet-hg104-512-coco-tf2

CenterNet model from "Objects as Points" with the Hourglass-104 backbone trained on COCO resized to 512x512

Detection,Coco,TensorFlow-2,Centernet

#### centernet-mobilenet-v2-fpn-512-coco-tf2

CenterNet model from "Objects as Points" with the MobileNetV2 backbone trained on COCO resized to 512x512

Detection,Coco,TensorFlow-2,Centernet,Mobilenet

#### centernet-resnet101-v1-fpn-512-coco-tf2

CenterNet model from "Objects as Points" with the ResNet-101v1 backbone + FPN trained on COCO resized to 512x512

Detection,Coco,TensorFlow-2,Centernet,Resnet

#### centernet-resnet50-v1-fpn-512-coco-tf2

CenterNet model from "Objects as Points" with the ResNet-50-v1 backbone + FPN trained on COCO resized to 512x512

Detection,Coco,TensorFlow-2,Centernet,Resnet

#### centernet-resnet50-v2-512-coco-tf2

CenterNet model from "Objects as Points" with the ResNet-50v2 backbone trained on COCO resized to 512x512

Detection,Coco,TensorFlow-2,Centernet,Resnet

#### classification-transformer-torch

Hugging Face Transformers model for image classification

Classification,Logits,Embeddings,PyTorch,Transformers

#### clip-vit-base32-torch

CLIP text/image encoder from "Learning Transferable Visual Models From Natural Language Supervision" trained on 400M text-image pairs

Classification,Logits,Embeddings,PyTorch,Clip,Zero-shot

#### deeplabv3-cityscapes-tf

DeepLabv3+ semantic segmentation model from "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation" with Xception backbone trained on the Cityscapes dataset

Segmentation,Cityscapes,TensorFlow,Deeplabv3

#### deeplabv3-mnv2-cityscapes-tf

DeepLabv3+ semantic segmentation model from "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation" with MobileNetV2 backbone trained on the Cityscapes dataset

Segmentation,Cityscapes,TensorFlow,Deeplabv3

#### deeplabv3-resnet101-coco-torch

DeepLabV3 model from "Rethinking Atrous Convolution for Semantic Image Segmentation" with ResNet-101 backbone trained on COCO

Segmentation,Coco,PyTorch,Resnet,Deeplabv3

#### deeplabv3-resnet50-coco-torch

DeepLabV3 model from "Rethinking Atrous Convolution for Semantic Image Segmentation" with ResNet-50 backbone trained on COCO

Segmentation,Coco,PyTorch,Resnet,Deeplabv3

#### densenet121-imagenet-torch

Densenet-121 model from "Densely Connected Convolutional Networks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet

#### densenet161-imagenet-torch

Densenet-161 model from "Densely Connected Convolutional Networks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet

#### densenet169-imagenet-torch

Densenet-169 model from "Densely Connected Convolutional Networks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet

#### densenet201-imagenet-torch

Densenet-201 model from "Densely Connected Convolutional Networks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet

#### depth-estimation-transformer-torch

Hugging Face Transformers model for monocular depth estimation

Depth,PyTorch,Transformers

#### detection-transformer-torch

Hugging Face Transformers model for object detection

Detection,Logits,Embeddings,PyTorch,Transformers

#### dinov2-vitb14-reg-torch

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-B/14 distilled

Embeddings,PyTorch,Dinov2

#### dinov2-vitb14-torch

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-B/14 distilled

Embeddings,PyTorch,Dinov2

#### dinov2-vitg14-reg-torch

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-g/14

Embeddings,PyTorch,Dinov2

#### dinov2-vitg14-torch

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-g/14

Embeddings,PyTorch,Dinov2

#### dinov2-vitl14-reg-torch

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-L/14 distilled

Embeddings,PyTorch,Dinov2

#### dinov2-vitl14-torch

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-L/14 distilled

Embeddings,PyTorch,Dinov2

#### dinov2-vits14-reg-torch

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-S/14 distilled

Embeddings,PyTorch,Dinov2

#### dinov2-vits14-torch

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-S/14 distilled

Embeddings,PyTorch,Dinov2

#### efficientdet-d0-512-coco-tf2

EfficientDet-D0 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 512x512

Detection,Coco,TensorFlow-2,Efficientdet

#### efficientdet-d0-coco-tf1

EfficientDet-D0 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO

Detection,Coco,TensorFlow-1,Efficientdet

#### efficientdet-d1-640-coco-tf2

EfficientDet-D1 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 640x640

Detection,Coco,TensorFlow-2,Efficientdet

#### efficientdet-d1-coco-tf1

EfficientDet-D1 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO

Detection,Coco,TensorFlow-1,Efficientdet

#### efficientdet-d2-768-coco-tf2

EfficientDet-D2 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 768x768

Detection,Coco,TensorFlow-2,Efficientdet

#### efficientdet-d2-coco-tf1

EfficientDet-D2 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO

Detection,Coco,TensorFlow-1,Efficientdet

#### efficientdet-d3-896-coco-tf2

EfficientDet-D3 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 896x896

Detection,Coco,TensorFlow-2,Efficientdet

#### efficientdet-d3-coco-tf1

EfficientDet-D3 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO

Detection,Coco,TensorFlow-1,Efficientdet

#### efficientdet-d4-1024-coco-tf2

EfficientDet-D4 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 1024x1024

Detection,Coco,TensorFlow-2,Efficientdet

#### efficientdet-d4-coco-tf1

EfficientDet-D4 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO

Detection,Coco,TensorFlow-1,Efficientdet

#### efficientdet-d5-1280-coco-tf2

EfficientDet-D5 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 1280x1280

Detection,Coco,TensorFlow-2,Efficientdet

#### efficientdet-d5-coco-tf1

EfficientDet-D5 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO

Detection,Coco,TensorFlow-1,Efficientdet

#### efficientdet-d6-1280-coco-tf2

EfficientDet-D6 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 1280x1280

Detection,Coco,TensorFlow-2,Efficientdet

#### efficientdet-d6-coco-tf1

EfficientDet-D6 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO

Detection,Coco,TensorFlow-1,Efficientdet

#### efficientdet-d7-1536-coco-tf2

EfficientDet-D7 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 1536x1536

Detection,Coco,TensorFlow-2,Efficientdet

#### faster-rcnn-inception-resnet-atrous-v2-coco-tf

Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" atrous version with Inception backbone trained on COCO

Detection,Coco,TensorFlow,Faster-rcnn,Inception,Resnet

#### faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf

Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" atrous version with low-proposals and Inception backbone trained on COCO

Detection,Coco,TensorFlow,Faster-rcnn,Inception,Resnet

#### faster-rcnn-inception-v2-coco-tf

Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with Inception v2 backbone trained on COCO

Detection,Coco,TensorFlow,Faster-rcnn,Inception

#### faster-rcnn-nas-coco-tf

Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with NAS-net backbone trained on COCO

Detection,Coco,TensorFlow,Faster-rcnn

#### faster-rcnn-nas-lowproposals-coco-tf

Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with low-proposals and NAS-net backbone trained on COCO

Detection,Coco,TensorFlow,Faster-rcnn

#### faster-rcnn-resnet101-coco-tf

Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with ResNet-101 backbone trained on COCO

Detection,Coco,TensorFlow,Faster-rcnn,Resnet

#### faster-rcnn-resnet101-lowproposals-coco-tf

Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with low-proposals and ResNet-101 backbone trained on COCO

Detection,Coco,TensorFlow,Faster-rcnn,Resnet

#### faster-rcnn-resnet50-coco-tf

Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with ResNet-50 backbone trained on COCO

Detection,Coco,TensorFlow,Faster-rcnn,Resnet

#### faster-rcnn-resnet50-fpn-coco-torch

Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with ResNet-50 FPN backbone trained on COCO

Detection,Coco,PyTorch,Faster-rcnn,Resnet

#### faster-rcnn-resnet50-lowproposals-coco-tf

Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with low-proposals and ResNet-50 backbone trained on COCO

Detection,Coco,TensorFlow,Faster-rcnn,Resnet

#### fcn-resnet101-coco-torch

FCN model from "Fully Convolutional Networks for Semantic Segmentation" with ResNet-101 backbone trained on COCO

Segmentation,Coco,PyTorch,Fcn,Resnet

#### fcn-resnet50-coco-torch

FCN model from "Fully Convolutional Networks for Semantic Segmentation" with ResNet-50 backbone trained on COCO

Segmentation,Coco,PyTorch,Fcn,Resnet

#### googlenet-imagenet-torch

GoogLeNet (Inception v1) model from "Going Deeper with Convolutions" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Googlenet

#### inception-resnet-v2-imagenet-tf1

Inception v2 model from "Rethinking the Inception Architecture for Computer Vision" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Inception,Resnet

#### inception-v3-imagenet-torch

Inception v3 model from "Rethinking the Inception Architecture for Computer Vision" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Inception

#### inception-v4-imagenet-tf1

Inception v4 model from "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Inception

#### keypoint-rcnn-resnet50-fpn-coco-torch

Keypoint R-CNN model from "Mask R-CNN" with ResNet-50 FPN backbone trained on COCO

Keypoints,Coco,PyTorch,Keypoint-rcnn,Resnet

#### mask-rcnn-inception-resnet-v2-atrous-coco-tf

Mask R-CNN model from "Mask R-CNN" atrous version with Inception backbone trained on COCO

Instances,Coco,TensorFlow,Mask-rcnn,Inception,Resnet

#### mask-rcnn-inception-v2-coco-tf

Mask R-CNN model from "Mask R-CNN" with Inception backbone trained on COCO

Instances,Coco,TensorFlow,Mask-rcnn,Inception

#### mask-rcnn-resnet101-atrous-coco-tf

Mask R-CNN model from "Mask R-CNN" atrous version with ResNet-101 backbone trained on COCO

Instances,Coco,TensorFlow,Mask-rcnn,Resnet

#### mask-rcnn-resnet50-atrous-coco-tf

Mask R-CNN model from "Mask R-CNN" atrous version with ResNet-50 backbone trained on COCO

Instances,Coco,TensorFlow,Mask-rcnn,Resnet

#### mask-rcnn-resnet50-fpn-coco-torch

Mask R-CNN model from "Mask R-CNN" with ResNet-50 FPN backbone trained on COCO

Instances,Coco,PyTorch,Mask-rcnn,Resnet

#### med-sam-2-video-torch

Fine-tuned SAM2-hiera-tiny model from "Medical SAM 2 - Segment Medical Images as Video via Segment Anything Model 2"

Segment-anything,PyTorch,Zero-shot,Video,Med-sam

#### mnasnet0.5-imagenet-torch

MNASNet model from from "MnasNet: Platform-Aware Neural Architecture Search for Mobile" with depth multiplier of 0.5 trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Mnasnet

#### mnasnet1.0-imagenet-torch

MNASNet model from "MnasNet: Platform-Aware Neural Architecture Search for Mobile" with depth multiplier of 1.0 trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Mnasnet

#### mobilenet-v2-imagenet-tf1

MobileNetV2 model from "MobileNetV2: Inverted Residuals and Linear Bottlenecks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Mobilenet

#### mobilenet-v2-imagenet-torch

MobileNetV2 model from "MobileNetV2: Inverted Residuals and Linear Bottlenecks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Mobilenet

#### open-clip-torch

OPEN CLIP text/image encoder from "Learning Transferable Visual Models From Natural Language Supervision" trained on 400M text-image pairs

Classification,Logits,Embeddings,PyTorch,Clip,Zero-shot

#### resnet-v1-50-imagenet-tf1

ResNet-50 v1 model from "Deep Residual Learning for Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Resnet

#### resnet-v2-50-imagenet-tf1

ResNet-50 v2 model from "Deep Residual Learning for Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Resnet

#### resnet101-imagenet-torch

ResNet-101 model from "Deep Residual Learning for Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet

#### resnet152-imagenet-torch

ResNet-152 model from "Deep Residual Learning for Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet

#### resnet18-imagenet-torch

ResNet-18 model from "Deep Residual Learning for Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet

#### resnet34-imagenet-torch

ResNet-34 model from "Deep Residual Learning for Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet

#### resnet50-imagenet-torch

ResNet-50 model from "Deep Residual Learning for Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet

#### resnext101-32x8d-imagenet-torch

ResNeXt-101 32x8d model from "Aggregated Residual Transformations for Deep Neural Networks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Resnext

#### resnext50-32x4d-imagenet-torch

ResNeXt-50 32x4d model from "Aggregated Residual Transformations for Deep Neural Networks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Resnext

#### retinanet-resnet50-fpn-coco-torch

RetinaNet model from "Focal Loss for Dense Object Detection" with ResNet-50 FPN backbone trained on COCO

Detection,Coco,PyTorch,Retinanet,Resnet

#### rfcn-resnet101-coco-tf

R-FCN object detection model from "R-FCN: Object Detection via Region-based Fully Convolutional Networks" with ResNet-101 backbone trained on COCO

Detection,Coco,TensorFlow,Rfcn,Resnet

#### rtdetr-l-coco-torch

RT-DETR-l model trained on COCO

Detection,Coco,PyTorch,Transformer,Rtdetr

#### rtdetr-x-coco-torch

RT-DETR-x model trained on COCO

Detection,Coco,PyTorch,Transformer,Rtdetr

#### segment-anything-2-hiera-base-plus-image-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot

#### segment-anything-2-hiera-base-plus-video-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot,Video

#### segment-anything-2-hiera-large-image-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot

#### segment-anything-2-hiera-large-video-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot,Video

#### segment-anything-2-hiera-small-image-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot

#### segment-anything-2-hiera-small-video-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot,Video

#### segment-anything-2-hiera-tiny-image-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot

#### segment-anything-2-hiera-tiny-video-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot,Video

#### segment-anything-2.1-hiera-base-plus-image-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot

#### segment-anything-2.1-hiera-base-plus-video-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot,Video

#### segment-anything-2.1-hiera-large-image-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot

#### segment-anything-2.1-hiera-large-video-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot,Video

#### segment-anything-2.1-hiera-small-image-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot

#### segment-anything-2.1-hiera-small-video-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot,Video

#### segment-anything-2.1-hiera-tiny-image-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot

#### segment-anything-2.1-hiera-tiny-video-torch

Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"

Segment-anything,PyTorch,Zero-shot,Video

#### segment-anything-vitb-torch

Segment Anything Model (SAM) from "Segment Anything" with ViT-B/16 backbone trained on SA-1B

Segment-anything,Sa-1b,PyTorch,Zero-shot

#### segment-anything-vith-torch

Segment Anything Model (SAM) from "Segment Anything" with ViT-H/16 backbone trained on SA-1B

Segment-anything,Sa-1b,PyTorch,Zero-shot

#### segment-anything-vitl-torch

Segment Anything Model (SAM) from "Segment Anything" with ViT-L/16 backbone trained on SA-1B

Segment-anything,Sa-1b,PyTorch,Zero-shot

#### segmentation-transformer-torch

Hugging Face Transformers model for semantic segmentation

Segmentation,PyTorch,Transformers

#### shufflenetv2-0.5x-imagenet-torch

ShuffleNetV2 model from "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design" with 0.5x output channels trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Shufflenet

#### shufflenetv2-1.0x-imagenet-torch

ShuffleNetV2 model from "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design" with 1.0x output channels trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Shufflenet

#### squeezenet-1.1-imagenet-torch

SqueezeNet 1.1 model from "the official SqueezeNet repo" trained on ImageNet

Classification,Imagenet,PyTorch,Squeezenet

#### squeezenet-imagenet-torch

SqueezeNet model from "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and" trained on ImageNet

Classification,Imagenet,PyTorch,Squeezenet

#### ssd-inception-v2-coco-tf

Inception Single Shot Detector model from "SSD: Single Shot MultiBox Detector" trained on COCO

Detection,Coco,TensorFlow,Ssd,Inception

#### ssd-mobilenet-v1-coco-tf

Single Shot Detector model from "SSD: Single Shot MultiBox Detector" with MobileNetV1 backbone trained on COCO

Detection,Coco,TensorFlow,Ssd,Mobilenet

#### ssd-mobilenet-v1-fpn-640-coco17

MobileNetV1 model from "MobileNetV2: Inverted Residuals and Linear Bottlenecks" resized to 640x640

Detection,Coco,TensorFlow-2,Ssd,Mobilenet

#### ssd-mobilenet-v1-fpn-coco-tf

FPN Single Shot Detector model from "SSD: Single Shot MultiBox Detector" with MobileNetV1 backbone trained on COCO

Detection,Coco,TensorFlow,Ssd,Mobilenet

#### ssd-mobilenet-v2-320-coco17

MobileNetV2 model from "MobileNetV2: Inverted Residuals and Linear Bottlenecks" resized to 320x320

Detection,Coco,TensorFlow-2,Ssd,Mobilenet

#### ssd-resnet50-fpn-coco-tf

FPN Single Shot Detector model from "SSD: Single Shot MultiBox Detector" with ResNet-50 backbone trained on COCO

Detection,Coco,TensorFlow,Ssd,Resnet

#### vgg11-bn-imagenet-torch

VGG-11 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" with batch normalization trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg

#### vgg11-imagenet-torch

VGG-11 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg

#### vgg13-bn-imagenet-torch

VGG-13 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" with batch normalization trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg

#### vgg13-imagenet-torch

VGG-13 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg

#### vgg16-bn-imagenet-torch

VGG-16 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" with batch normalization trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg

#### vgg16-imagenet-tf1

VGG-16 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Vgg

#### vgg16-imagenet-torch

VGG-16 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg

#### vgg19-bn-imagenet-torch

VGG-19 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" with batch normalization trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg

#### vgg19-imagenet-torch

VGG-19 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg

#### wide-resnet101-2-imagenet-torch

Wide ResNet-101-2 model from "Wide Residual Networks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Wide-resnet

#### wide-resnet50-2-imagenet-torch

Wide ResNet-50-2 model from "Wide Residual Networks" trained on ImageNet

Classification,Embeddings,Logits,Imagenet,PyTorch,Wide-resnet

#### yolo-nas-torch

YOLO-NAS is an open-source training library for advanced computer vision models. It specializes in accuracy and efficiency, supporting tasks like object detection

Detection,PyTorch,Yolo

#### yolo-v2-coco-tf1

YOLOv2 model from "YOLO9000: Better, Faster, Stronger" trained on COCO

Detection,Coco,TensorFlow-1,Yolo

#### yolo11l-coco-torch

YOLO11-L model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolo11l-seg-coco-torch

YOLO11-L Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolo11m-coco-torch

YOLO11-M model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolo11m-seg-coco-torch

YOLO11-M Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolo11n-coco-torch

YOLO11-N model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolo11n-seg-coco-torch

YOLO11-N Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolo11s-coco-torch

YOLO11-S model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolo11s-seg-coco-torch

YOLO11-S Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolo11x-coco-torch

YOLO11-X model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolo11x-seg-coco-torch

YOLO11-X Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolov10l-coco-torch

YOLOv10-L model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov10m-coco-torch

YOLOv10-M model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov10n-coco-torch

YOLOv10-N model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov10s-coco-torch

YOLOv10-S model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov10x-coco-torch

YOLOv10-X model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov5l-coco-torch

Ultralytics YOLOv5l model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov5m-coco-torch

Ultralytics YOLOv5m model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov5n-coco-torch

Ultralytics YOLOv5n model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov5s-coco-torch

Ultralytics YOLOv5s model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov5x-coco-torch

Ultralytics YOLOv5x model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov8l-coco-torch

Ultralytics YOLOv8l model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov8l-obb-dotav1-torch

YOLOv8l Oriented Bounding Box model

Detection,PyTorch,Yolo,Polylines,Obb

#### yolov8l-oiv7-torch

Ultralytics YOLOv8l model trained Open Images v7

Detection,Oiv7,PyTorch,Yolo

#### yolov8l-seg-coco-torch

Ultralytics YOLOv8l Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolov8l-world-torch

YOLOv8l-World model

Detection,PyTorch,Yolo,Zero-shot

#### yolov8m-coco-torch

Ultralytics YOLOv8m model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov8m-obb-dotav1-torch

YOLOv8m Oriented Bounding Box model

Detection,PyTorch,Yolo,Polylines,Obb

#### yolov8m-oiv7-torch

Ultralytics YOLOv8m model trained Open Images v7

Detection,Oiv7,PyTorch,Yolo

#### yolov8m-seg-coco-torch

Ultralytics YOLOv8m Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolov8m-world-torch

YOLOv8m-World model

Detection,PyTorch,Yolo,Zero-shot

#### yolov8n-coco-torch

Ultralytics YOLOv8n model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov8n-obb-dotav1-torch

YOLOv8n Oriented Bounding Box model

Detection,PyTorch,Yolo,Polylines,Obb

#### yolov8n-oiv7-torch

Ultralytics YOLOv8n model trained on Open Images v7

Detection,Oiv7,PyTorch,Yolo

#### yolov8n-seg-coco-torch

Ultralytics YOLOv8n Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolov8s-coco-torch

Ultralytics YOLOv8s model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov8s-obb-dotav1-torch

YOLOv8s Oriented Bounding Box model

Detection,PyTorch,Yolo,Polylines,Obb

#### yolov8s-oiv7-torch

Ultralytics YOLOv8s model trained on Open Images v7

Detection,Oiv7,PyTorch,Yolo

#### yolov8s-seg-coco-torch

Ultralytics YOLOv8s Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolov8s-world-torch

YOLOv8s-World model

Detection,PyTorch,Yolo,Zero-shot

#### yolov8x-coco-torch

Ultralytics YOLOv8x model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov8x-obb-dotav1-torch

YOLOv8x Oriented Bounding Box model

Detection,PyTorch,Yolo,Polylines,Obb

#### yolov8x-oiv7-torch

Ultralytics YOLOv8x model trained Open Images v7

Detection,Oiv7,PyTorch,Yolo

#### yolov8x-seg-coco-torch

Ultralytics YOLOv8x Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolov8x-world-torch

YOLOv8x-World model

Detection,PyTorch,Yolo,Zero-shot

#### yolov9c-coco-torch

YOLOv9-C model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov9c-seg-coco-torch

YOLOv9-C Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### yolov9e-coco-torch

YOLOv9-E model trained on COCO

Detection,Coco,PyTorch,Yolo

#### yolov9e-seg-coco-torch

YOLOv9-E Segmentation model trained on COCO

Segmentation,Coco,PyTorch,Yolo

#### zero-shot-classification-transformer-torch

Hugging Face Transformers model for zero-shot image classification

Classification,Logits,Embeddings,PyTorch,Transformers,Zero-shot

#### zero-shot-detection-transformer-torch

Hugging Face Transformers model for zero-shot object detection

Detection,Logits,Embeddings,PyTorch,Transformers,Zero-shot

## Torch models [Â¶](\#torch-models "Permalink to this headline")

### alexnet-imagenet-torch [Â¶](\#alexnet-imagenet-torch "Permalink to this headline")

AlexNet model architecture from [One weird trick for parallelizing convolutional neural networks](https://arxiv.org/abs/1404.5997) trained on ImageNet.

**Details**

- Model name: `alexnet-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 233.10 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, alexnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("alexnet-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### classification-transformer-torch [Â¶](\#classification-transformer-torch "Permalink to this headline")

Hugging Face Transformers model for image classification.

**Details**

- Model name: `classification-transformer-torch`

- Model source: [https://huggingface.co/docs/transformers/tasks/image\_classification](https://huggingface.co/docs/transformers/tasks/image_classification)

- Exposes embeddings? yes

- Tags: `classification, logits, embeddings, torch, transformers`


**Requirements**

- Packages: `torch, torchvision, transformers`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("classification-transformer-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### clip-vit-base32-torch [Â¶](\#clip-vit-base32-torch "Permalink to this headline")

CLIP text/image encoder from [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) trained on 400M text-image pairs.

**Details**

- Model name: `clip-vit-base32-torch`

- Model source: [https://github.com/openai/CLIP](https://github.com/openai/CLIP)

- Model size: 337.58 MB

- Exposes embeddings? yes

- Tags: `classification, logits, embeddings, torch, clip, zero-shot`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("clip-vit-base32-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

#
# Make zero-shot predictions with custom classes
#

model = foz.load_zoo_model(
    "clip-vit-base32-torch",
    text_prompt="A photo of a",
    classes=["person", "dog", "cat", "bird", "car", "tree", "chair"],
)

dataset.apply_model(model, label_field="predictions")
session.refresh()

```

### deeplabv3-resnet101-coco-torch [Â¶](\#deeplabv3-resnet101-coco-torch "Permalink to this headline")

DeepLabV3 model from [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587) with ResNet-101 backbone trained on COCO.

**Details**

- Model name: `deeplabv3-resnet101-coco-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 233.22 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, resnet, deeplabv3`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("deeplabv3-resnet101-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### deeplabv3-resnet50-coco-torch [Â¶](\#deeplabv3-resnet50-coco-torch "Permalink to this headline")

DeepLabV3 model from [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587) with ResNet-50 backbone trained on COCO.

**Details**

- Model name: `deeplabv3-resnet50-coco-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 160.51 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, resnet, deeplabv3`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("deeplabv3-resnet50-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### densenet121-imagenet-torch [Â¶](\#densenet121-imagenet-torch "Permalink to this headline")

Densenet-121 model from [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf) trained on ImageNet.

**Details**

- Model name: `densenet121-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 30.84 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, densenet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("densenet121-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### densenet161-imagenet-torch [Â¶](\#densenet161-imagenet-torch "Permalink to this headline")

Densenet-161 model from [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf) trained on ImageNet.

**Details**

- Model name: `densenet161-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 110.37 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, densenet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("densenet161-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### densenet169-imagenet-torch [Â¶](\#densenet169-imagenet-torch "Permalink to this headline")

Densenet-169 model from [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf) trained on ImageNet.

**Details**

- Model name: `densenet169-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 54.71 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, densenet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("densenet169-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### densenet201-imagenet-torch [Â¶](\#densenet201-imagenet-torch "Permalink to this headline")

Densenet-201 model from [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf) trained on ImageNet.

**Details**

- Model name: `densenet201-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 77.37 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, densenet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("densenet201-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### depth-estimation-transformer-torch [Â¶](\#depth-estimation-transformer-torch "Permalink to this headline")

Hugging Face Transformers model for monocular depth estimation.

**Details**

- Model name: `depth-estimation-transformer-torch`

- Model source: [https://huggingface.co/docs/transformers/tasks/monocular\_depth\_estimation](https://huggingface.co/docs/transformers/tasks/monocular_depth_estimation)

- Exposes embeddings? no

- Tags: `depth, torch, transformers`


**Requirements**

- Packages: `torch, torchvision, transformers`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("depth-estimation-transformer-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### detection-transformer-torch [Â¶](\#detection-transformer-torch "Permalink to this headline")

Hugging Face Transformers model for object detection.

**Details**

- Model name: `detection-transformer-torch`

- Model source: [https://huggingface.co/docs/transformers/tasks/object\_detection](https://huggingface.co/docs/transformers/tasks/object_detection)

- Exposes embeddings? yes

- Tags: `detection, logits, embeddings, torch, transformers`


**Requirements**

- Packages: `torch, torchvision, transformers`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("detection-transformer-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### dinov2-vitb14-reg-torch [Â¶](\#dinov2-vitb14-reg-torch "Permalink to this headline")

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-B/14 distilled.

**Details**

- Model name: `dinov2-vitb14-reg-torch`

- Model source: [https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)

- Model size: 330.35 MB

- Exposes embeddings? yes

- Tags: `embeddings, torch, dinov2`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("dinov2-vitb14-reg-torch")

embeddings = dataset.compute_embeddings(model)

```

### dinov2-vitb14-torch [Â¶](\#dinov2-vitb14-torch "Permalink to this headline")

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-B/14 distilled.

**Details**

- Model name: `dinov2-vitb14-torch`

- Model source: [https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)

- Model size: 330.33 MB

- Exposes embeddings? yes

- Tags: `embeddings, torch, dinov2`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("dinov2-vitb14-torch")

embeddings = dataset.compute_embeddings(model)

```

### dinov2-vitg14-reg-torch [Â¶](\#dinov2-vitg14-reg-torch "Permalink to this headline")

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-g/14.

**Details**

- Model name: `dinov2-vitg14-reg-torch`

- Model source: [https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)

- Model size: 4.23 GB

- Exposes embeddings? yes

- Tags: `embeddings, torch, dinov2`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("dinov2-vitg14-reg-torch")

embeddings = dataset.compute_embeddings(model)

```

### dinov2-vitg14-torch [Â¶](\#dinov2-vitg14-torch "Permalink to this headline")

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-g/14.

**Details**

- Model name: `dinov2-vitg14-torch`

- Model source: [https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)

- Model size: 4.23 GB

- Exposes embeddings? yes

- Tags: `embeddings, torch, dinov2`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("dinov2-vitg14-torch")

embeddings = dataset.compute_embeddings(model)

```

### dinov2-vitl14-reg-torch [Â¶](\#dinov2-vitl14-reg-torch "Permalink to this headline")

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-L/14 distilled.

**Details**

- Model name: `dinov2-vitl14-reg-torch`

- Model source: [https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)

- Model size: 1.13 GB

- Exposes embeddings? yes

- Tags: `embeddings, torch, dinov2`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("dinov2-vitl14-reg-torch")

embeddings = dataset.compute_embeddings(model)

```

### dinov2-vitl14-torch [Â¶](\#dinov2-vitl14-torch "Permalink to this headline")

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-L/14 distilled.

**Details**

- Model name: `dinov2-vitl14-torch`

- Model source: [https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)

- Model size: 1.13 GB

- Exposes embeddings? yes

- Tags: `embeddings, torch, dinov2`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("dinov2-vitl14-torch")

embeddings = dataset.compute_embeddings(model)

```

### dinov2-vits14-reg-torch [Â¶](\#dinov2-vits14-reg-torch "Permalink to this headline")

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-S/14 distilled.

**Details**

- Model name: `dinov2-vits14-reg-torch`

- Model source: [https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)

- Model size: 84.20 MB

- Exposes embeddings? yes

- Tags: `embeddings, torch, dinov2`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("dinov2-vits14-reg-torch")

embeddings = dataset.compute_embeddings(model)

```

### dinov2-vits14-torch [Â¶](\#dinov2-vits14-torch "Permalink to this headline")

DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-S/14 distilled.

**Details**

- Model name: `dinov2-vits14-torch`

- Model source: [https://github.com/facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)

- Model size: 84.19 MB

- Exposes embeddings? yes

- Tags: `embeddings, torch, dinov2`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("dinov2-vits14-torch")

embeddings = dataset.compute_embeddings(model)

```

### faster-rcnn-resnet50-fpn-coco-torch [Â¶](\#faster-rcnn-resnet50-fpn-coco-torch "Permalink to this headline")

Faster R-CNN model from [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) with ResNet-50 FPN backbone trained on COCO.

**Details**

- Model name: `faster-rcnn-resnet50-fpn-coco-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 159.74 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, faster-rcnn, resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("faster-rcnn-resnet50-fpn-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### fcn-resnet101-coco-torch [Â¶](\#fcn-resnet101-coco-torch "Permalink to this headline")

FCN model from [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1411.4038) with ResNet-101 backbone trained on COCO.

**Details**

- Model name: `fcn-resnet101-coco-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 207.71 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, fcn, resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("fcn-resnet101-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### fcn-resnet50-coco-torch [Â¶](\#fcn-resnet50-coco-torch "Permalink to this headline")

FCN model from [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1411.4038) with ResNet-50 backbone trained on COCO.

**Details**

- Model name: `fcn-resnet50-coco-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 135.01 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, fcn, resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("fcn-resnet50-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### googlenet-imagenet-torch [Â¶](\#googlenet-imagenet-torch "Permalink to this headline")

GoogLeNet (Inception v1) model from [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842) trained on ImageNet.

**Details**

- Model name: `googlenet-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 49.73 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, googlenet`


**Requirements**

- Packages: `scipy, torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("googlenet-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### inception-v3-imagenet-torch [Â¶](\#inception-v3-imagenet-torch "Permalink to this headline")

Inception v3 model from [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567) trained on ImageNet.

**Details**

- Model name: `inception-v3-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 103.81 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, inception`


**Requirements**

- Packages: `scipy, torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("inception-v3-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### keypoint-rcnn-resnet50-fpn-coco-torch [Â¶](\#keypoint-rcnn-resnet50-fpn-coco-torch "Permalink to this headline")

Keypoint R-CNN model from [Mask R-CNN](https://arxiv.org/abs/1703.06870) with ResNet-50 FPN backbone trained on COCO.

**Details**

- Model name: `keypoint-rcnn-resnet50-fpn-coco-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 226.05 MB

- Exposes embeddings? no

- Tags: `keypoints, coco, torch, keypoint-rcnn, resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("keypoint-rcnn-resnet50-fpn-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### mask-rcnn-resnet50-fpn-coco-torch [Â¶](\#mask-rcnn-resnet50-fpn-coco-torch "Permalink to this headline")

Mask R-CNN model from [Mask R-CNN](https://arxiv.org/abs/1703.06870) with ResNet-50 FPN backbone trained on COCO.

**Details**

- Model name: `mask-rcnn-resnet50-fpn-coco-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 169.84 MB

- Exposes embeddings? no

- Tags: `instances, coco, torch, mask-rcnn, resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("mask-rcnn-resnet50-fpn-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### med-sam-2-video-torch [Â¶](\#med-sam-2-video-torch "Permalink to this headline")

Fine-tuned SAM2-hiera-tiny model from [Medical SAM 2 - Segment Medical Images as Video via Segment Anything Model 2](https://arxiv.org/abs/2408.00874).

**Details**

- Model name: `med-sam-2-video-torch`

- Model source: [https://github.com/MedicineToken/Medical-SAM2](https://github.com/MedicineToken/Medical-SAM2)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot, video, med-SAM`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz
from fiftyone import ViewField as F
from fiftyone.utils.huggingface import load_from_hub

dataset = load_from_hub("Voxel51/BTCV-CT-as-video-MedSAM2-dataset")[:2]

# Retaining detections from a single frame in the middle
# Note that SAM2 only propagates segmentation masks forward in a video
(
    dataset
    .match_frames(F("frame_number") != 100)
    .set_field("frames.gt_detections", None)
    .save()
)

model = foz.load_zoo_model("med-sam-2-video-torch")

# Segment inside boxes and propagate to all frames
dataset.apply_model(
    model,
    label_field="pred_segmentations",
    prompt_field="frames.gt_detections",
)

session = fo.launch_app(dataset)

```

### mnasnet0.5-imagenet-torch [Â¶](\#mnasnet0-5-imagenet-torch "Permalink to this headline")

MNASNet model from from [MnasNet: Platform-Aware Neural Architecture Search for Mobile](https://arxiv.org/abs/1807.11626) with depth multiplier of 0.5 trained on ImageNet.

**Details**

- Model name: `mnasnet0.5-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 8.59 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, mnasnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("mnasnet0.5-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### mnasnet1.0-imagenet-torch [Â¶](\#mnasnet1-0-imagenet-torch "Permalink to this headline")

MNASNet model from [MnasNet: Platform-Aware Neural Architecture Search for Mobile](https://arxiv.org/abs/1807.11626) with depth multiplier of 1.0 trained on ImageNet.

**Details**

- Model name: `mnasnet1.0-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 16.92 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, mnasnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("mnasnet1.0-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### mobilenet-v2-imagenet-torch [Â¶](\#mobilenet-v2-imagenet-torch "Permalink to this headline")

MobileNetV2 model from [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381) trained on ImageNet.

**Details**

- Model name: `mobilenet-v2-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 13.55 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, mobilenet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("mobilenet-v2-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### open-clip-torch [Â¶](\#open-clip-torch "Permalink to this headline")

OPEN CLIP text/image encoder from [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) trained on 400M text-image pairs.

**Details**

- Model name: `open-clip-torch`

- Model source: [https://github.com/mlfoundations/open\_clip](https://github.com/mlfoundations/open_clip)

- Exposes embeddings? yes

- Tags: `classification, logits, embeddings, torch, clip, zero-shot`


**Requirements**

- Packages: `torch, torchvision, open_clip_torch`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("open-clip-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

#
# Make zero-shot predictions with custom classes
#

model = foz.load_zoo_model(
    "open-clip-torch",
    text_prompt="A photo of a",
    classes=["person", "dog", "cat", "bird", "car", "tree", "chair"],
)

dataset.apply_model(model, label_field="predictions")
session.refresh()

```

### resnet101-imagenet-torch [Â¶](\#resnet101-imagenet-torch "Permalink to this headline")

ResNet-101 model from [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) trained on ImageNet.

**Details**

- Model name: `resnet101-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 170.45 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("resnet101-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### resnet152-imagenet-torch [Â¶](\#resnet152-imagenet-torch "Permalink to this headline")

ResNet-152 model from [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) trained on ImageNet.

**Details**

- Model name: `resnet152-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 230.34 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("resnet152-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### resnet18-imagenet-torch [Â¶](\#resnet18-imagenet-torch "Permalink to this headline")

ResNet-18 model from [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) trained on ImageNet.

**Details**

- Model name: `resnet18-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 44.66 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("resnet18-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### resnet34-imagenet-torch [Â¶](\#resnet34-imagenet-torch "Permalink to this headline")

ResNet-34 model from [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) trained on ImageNet.

**Details**

- Model name: `resnet34-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 83.26 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("resnet34-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### resnet50-imagenet-torch [Â¶](\#resnet50-imagenet-torch "Permalink to this headline")

ResNet-50 model from [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) trained on ImageNet.

**Details**

- Model name: `resnet50-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 97.75 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("resnet50-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### resnext101-32x8d-imagenet-torch [Â¶](\#resnext101-32x8d-imagenet-torch "Permalink to this headline")

ResNeXt-101 32x8d model from [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431) trained on ImageNet.

**Details**

- Model name: `resnext101-32x8d-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 339.59 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, resnext`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("resnext101-32x8d-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### resnext50-32x4d-imagenet-torch [Â¶](\#resnext50-32x4d-imagenet-torch "Permalink to this headline")

ResNeXt-50 32x4d model from [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431) trained on ImageNet.

**Details**

- Model name: `resnext50-32x4d-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 95.79 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, resnext`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("resnext50-32x4d-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### retinanet-resnet50-fpn-coco-torch [Â¶](\#retinanet-resnet50-fpn-coco-torch "Permalink to this headline")

RetinaNet model from [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002) with ResNet-50 FPN backbone trained on COCO.

**Details**

- Model name: `retinanet-resnet50-fpn-coco-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 130.27 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, retinanet, resnet`


**Requirements**

- Packages: `torch, torchvision>=0.8.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("retinanet-resnet50-fpn-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### rtdetr-l-coco-torch [Â¶](\#rtdetr-l-coco-torch "Permalink to this headline")

RT-DETR-l model trained on COCO.

**Details**

- Model name: `rtdetr-l-coco-torch`

- Model source: [https://docs.ultralytics.com/models/rtdetr/](https://docs.ultralytics.com/models/rtdetr/)

- Model size: 63.43 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, transformer, rtdetr`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.2.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("rtdetr-l-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### rtdetr-x-coco-torch [Â¶](\#rtdetr-x-coco-torch "Permalink to this headline")

RT-DETR-x model trained on COCO.

**Details**

- Model name: `rtdetr-x-coco-torch`

- Model source: [https://docs.ultralytics.com/models/rtdetr/](https://docs.ultralytics.com/models/rtdetr/)

- Model size: 129.47 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, transformer, rtdetr`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.2.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("rtdetr-x-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### segment-anything-2-hiera-base-plus-image-torch [Â¶](\#segment-anything-2-hiera-base-plus-image-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2-hiera-base-plus-image-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-2-hiera-base-plus-image-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segment-anything-2-hiera-base-plus-video-torch [Â¶](\#segment-anything-2-hiera-base-plus-video-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2-hiera-base-plus-video-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot, video`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz
from fiftyone import ViewField as F

dataset = foz.load_zoo_dataset("quickstart-video", max_samples=2)

# Only retain detections in the first frame
(
    dataset
    .match_frames(F("frame_number") > 1)
    .set_field("frames.detections", None)
    .save()
)

model = foz.load_zoo_model("segment-anything-2-hiera-base-plus-video-torch")

# Segment inside boxes and propagate to all frames
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="frames.detections",  # can contain Detections or Keypoints
)

session = fo.launch_app(dataset)

```

### segment-anything-2-hiera-large-image-torch [Â¶](\#segment-anything-2-hiera-large-image-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2-hiera-large-image-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-2-hiera-large-image-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segment-anything-2-hiera-large-video-torch [Â¶](\#segment-anything-2-hiera-large-video-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2-hiera-large-video-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot, video`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz
from fiftyone import ViewField as F

dataset = foz.load_zoo_dataset("quickstart-video", max_samples=2)

# Only retain detections in the first frame
(
    dataset
    .match_frames(F("frame_number") > 1)
    .set_field("frames.detections", None)
    .save()
)

model = foz.load_zoo_model("segment-anything-2-hiera-large-video-torch")

# Segment inside boxes and propagate to all frames
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="frames.detections",  # can contain Detections or Keypoints
)

session = fo.launch_app(dataset)

```

### segment-anything-2-hiera-small-image-torch [Â¶](\#segment-anything-2-hiera-small-image-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2-hiera-small-image-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-2-hiera-small-image-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segment-anything-2-hiera-small-video-torch [Â¶](\#segment-anything-2-hiera-small-video-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2-hiera-small-video-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot, video`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz
from fiftyone import ViewField as F

dataset = foz.load_zoo_dataset("quickstart-video", max_samples=2)

# Only retain detections in the first frame
(
    dataset
    .match_frames(F("frame_number") > 1)
    .set_field("frames.detections", None)
    .save()
)

model = foz.load_zoo_model("segment-anything-2-hiera-small-video-torch")

# Segment inside boxes and propagate to all frames
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="frames.detections",  # can contain Detections or Keypoints
)

session = fo.launch_app(dataset)

```

### segment-anything-2-hiera-tiny-image-torch [Â¶](\#segment-anything-2-hiera-tiny-image-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2-hiera-tiny-image-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-2-hiera-tiny-image-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segment-anything-2-hiera-tiny-video-torch [Â¶](\#segment-anything-2-hiera-tiny-video-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2-hiera-tiny-video-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot, video`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz
from fiftyone import ViewField as F

dataset = foz.load_zoo_dataset("quickstart-video", max_samples=2)

# Only retain detections in the first frame
(
    dataset
    .match_frames(F("frame_number") > 1)
    .set_field("frames.detections", None)
    .save()
)

model = foz.load_zoo_model("segment-anything-2-hiera-tiny-video-torch")

# Segment inside boxes and propagate to all frames
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="frames.detections",  # can contain Detections or Keypoints
)

session = fo.launch_app(dataset)

```

### segment-anything-2.1-hiera-base-plus-image-torch [Â¶](\#segment-anything-2-1-hiera-base-plus-image-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2.1-hiera-base-plus-image-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-2.1-hiera-base-plus-image-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segment-anything-2.1-hiera-base-plus-video-torch [Â¶](\#segment-anything-2-1-hiera-base-plus-video-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2.1-hiera-base-plus-video-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot, video`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz
from fiftyone import ViewField as F

dataset = foz.load_zoo_dataset("quickstart-video", max_samples=2)

# Only retain detections in the first frame
(
    dataset
    .match_frames(F("frame_number") > 1)
    .set_field("frames.detections", None)
    .save()
)

model = foz.load_zoo_model("segment-anything-2.1-hiera-base-plus-video-torch")

# Segment inside boxes and propagate to all frames
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="frames.detections",  # can contain Detections or Keypoints
)

session = fo.launch_app(dataset)

```

### segment-anything-2.1-hiera-large-image-torch [Â¶](\#segment-anything-2-1-hiera-large-image-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2.1-hiera-large-image-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-2.1-hiera-large-image-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segment-anything-2.1-hiera-large-video-torch [Â¶](\#segment-anything-2-1-hiera-large-video-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2.1-hiera-large-video-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot, video`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz
from fiftyone import ViewField as F

dataset = foz.load_zoo_dataset("quickstart-video", max_samples=2)

# Only retain detections in the first frame
(
    dataset
    .match_frames(F("frame_number") > 1)
    .set_field("frames.detections", None)
    .save()
)

model = foz.load_zoo_model("segment-anything-2.1-hiera-large-video-torch")

# Segment inside boxes and propagate to all frames
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="frames.detections",  # can contain Detections or Keypoints
)

session = fo.launch_app(dataset)

```

### segment-anything-2.1-hiera-small-image-torch [Â¶](\#segment-anything-2-1-hiera-small-image-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2.1-hiera-small-image-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-2.1-hiera-small-image-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segment-anything-2.1-hiera-small-video-torch [Â¶](\#segment-anything-2-1-hiera-small-video-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2.1-hiera-small-video-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot, video`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz
from fiftyone import ViewField as F

dataset = foz.load_zoo_dataset("quickstart-video", max_samples=2)

# Only retain detections in the first frame
(
    dataset
    .match_frames(F("frame_number") > 1)
    .set_field("frames.detections", None)
    .save()
)

model = foz.load_zoo_model("segment-anything-2.1-hiera-small-video-torch")

# Segment inside boxes and propagate to all frames
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="frames.detections",  # can contain Detections or Keypoints
)

session = fo.launch_app(dataset)

```

### segment-anything-2.1-hiera-tiny-image-torch [Â¶](\#segment-anything-2-1-hiera-tiny-image-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2.1-hiera-tiny-image-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-2.1-hiera-tiny-image-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segment-anything-2.1-hiera-tiny-video-torch [Â¶](\#segment-anything-2-1-hiera-tiny-video-torch "Permalink to this headline")

Segment Anything Model 2 (SAM2) from [SAM2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714).

**Details**

- Model name: `segment-anything-2.1-hiera-tiny-video-torch`

- Model source: [https://ai.meta.com/sam2/](https://ai.meta.com/sam2/)

- Model size: 148.68 MB

- Exposes embeddings? no

- Tags: `segment-anything, torch, zero-shot, video`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz
from fiftyone import ViewField as F

dataset = foz.load_zoo_dataset("quickstart-video", max_samples=2)

# Only retain detections in the first frame
(
    dataset
    .match_frames(F("frame_number") > 1)
    .set_field("frames.detections", None)
    .save()
)

model = foz.load_zoo_model("segment-anything-2.1-hiera-tiny-video-torch")

# Segment inside boxes and propagate to all frames
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="frames.detections",  # can contain Detections or Keypoints
)

session = fo.launch_app(dataset)

```

### segment-anything-vitb-torch [Â¶](\#segment-anything-vitb-torch "Permalink to this headline")

Segment Anything Model (SAM) from [Segment Anything](https://arxiv.org/abs/2304.02643) with ViT-B/16 backbone trained on SA-1B.

**Details**

- Model name: `segment-anything-vitb-torch`

- Model source: [https://segment-anything.com](https://segment-anything.com)

- Model size: 715.34 KB

- Exposes embeddings? no

- Tags: `segment-anything, sa-1b, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision, segment-anything`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-vitb-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segment-anything-vith-torch [Â¶](\#segment-anything-vith-torch "Permalink to this headline")

Segment Anything Model (SAM) from [Segment Anything](https://arxiv.org/abs/2304.02643) with ViT-H/16 backbone trained on SA-1B.

**Details**

- Model name: `segment-anything-vith-torch`

- Model source: [https://segment-anything.com](https://segment-anything.com)

- Model size: 4.78 MB

- Exposes embeddings? no

- Tags: `segment-anything, sa-1b, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision, segment-anything`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-vith-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segment-anything-vitl-torch [Â¶](\#segment-anything-vitl-torch "Permalink to this headline")

Segment Anything Model (SAM) from [Segment Anything](https://arxiv.org/abs/2304.02643) with ViT-L/16 backbone trained on SA-1B.

**Details**

- Model name: `segment-anything-vitl-torch`

- Model source: [https://segment-anything.com](https://segment-anything.com)

- Model size: 2.33 MB

- Exposes embeddings? no

- Tags: `segment-anything, sa-1b, torch, zero-shot`


**Requirements**

- Packages: `torch, torchvision, segment-anything`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segment-anything-vitl-torch")

# Segment inside boxes
dataset.apply_model(
    model,
    label_field="segmentations",
    prompt_field="ground_truth",  # can contain Detections or Keypoints
)

# Full automatic segmentations
dataset.apply_model(model, label_field="auto")

session = fo.launch_app(dataset)

```

### segmentation-transformer-torch [Â¶](\#segmentation-transformer-torch "Permalink to this headline")

Hugging Face Transformers model for semantic segmentation.

**Details**

- Model name: `segmentation-transformer-torch`

- Model source: [https://huggingface.co/docs/transformers/tasks/semantic\_segmentation](https://huggingface.co/docs/transformers/tasks/semantic_segmentation)

- Exposes embeddings? no

- Tags: `segmentation, torch, transformers`


**Requirements**

- Packages: `torch, torchvision, transformers`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("segmentation-transformer-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### shufflenetv2-0.5x-imagenet-torch [Â¶](\#shufflenetv2-0-5x-imagenet-torch "Permalink to this headline")

ShuffleNetV2 model from [ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design](https://arxiv.org/abs/1807.11164) with 0.5x output channels trained on ImageNet.

**Details**

- Model name: `shufflenetv2-0.5x-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 5.28 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, shufflenet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("shufflenetv2-0.5x-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### shufflenetv2-1.0x-imagenet-torch [Â¶](\#shufflenetv2-1-0x-imagenet-torch "Permalink to this headline")

ShuffleNetV2 model from [ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design](https://arxiv.org/abs/1807.11164) with 1.0x output channels trained on ImageNet.

**Details**

- Model name: `shufflenetv2-1.0x-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 8.79 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, shufflenet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("shufflenetv2-1.0x-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### squeezenet-1.1-imagenet-torch [Â¶](\#squeezenet-1-1-imagenet-torch "Permalink to this headline")

SqueezeNet 1.1 model from [the official SqueezeNet repo](https://github.com/forresti/SqueezeNet/tree/master/SqueezeNet_v1.1) trained on ImageNet.

**Details**

- Model name: `squeezenet-1.1-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 4.74 MB

- Exposes embeddings? no

- Tags: `classification, imagenet, torch, squeezenet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("squeezenet-1.1-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### squeezenet-imagenet-torch [Â¶](\#squeezenet-imagenet-torch "Permalink to this headline")

SqueezeNet model from [SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size](https://arxiv.org/abs/1602.07360) trained on ImageNet.

**Details**

- Model name: `squeezenet-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 4.79 MB

- Exposes embeddings? no

- Tags: `classification, imagenet, torch, squeezenet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("squeezenet-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### vgg11-bn-imagenet-torch [Â¶](\#vgg11-bn-imagenet-torch "Permalink to this headline")

VGG-11 model from [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) with batch normalization trained on ImageNet.

**Details**

- Model name: `vgg11-bn-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 506.88 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, vgg`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("vgg11-bn-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### vgg11-imagenet-torch [Â¶](\#vgg11-imagenet-torch "Permalink to this headline")

VGG-11 model from [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) trained on ImageNet.

**Details**

- Model name: `vgg11-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 506.84 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, vgg`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("vgg11-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### vgg13-bn-imagenet-torch [Â¶](\#vgg13-bn-imagenet-torch "Permalink to this headline")

VGG-13 model from [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) with batch normalization trained on ImageNet.

**Details**

- Model name: `vgg13-bn-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 507.59 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, vgg`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("vgg13-bn-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### vgg13-imagenet-torch [Â¶](\#vgg13-imagenet-torch "Permalink to this headline")

VGG-13 model from [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) trained on ImageNet.

**Details**

- Model name: `vgg13-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 507.54 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, vgg`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("vgg13-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### vgg16-bn-imagenet-torch [Â¶](\#vgg16-bn-imagenet-torch "Permalink to this headline")

VGG-16 model from [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) with batch normalization trained on ImageNet.

**Details**

- Model name: `vgg16-bn-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 527.87 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, vgg`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("vgg16-bn-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### vgg16-imagenet-torch [Â¶](\#vgg16-imagenet-torch "Permalink to this headline")

VGG-16 model from [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) trained on ImageNet.

**Details**

- Model name: `vgg16-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 527.80 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, vgg`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("vgg16-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### vgg19-bn-imagenet-torch [Â¶](\#vgg19-bn-imagenet-torch "Permalink to this headline")

VGG-19 model from [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) with batch normalization trained on ImageNet.

**Details**

- Model name: `vgg19-bn-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 548.14 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, vgg`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("vgg19-bn-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### vgg19-imagenet-torch [Â¶](\#vgg19-imagenet-torch "Permalink to this headline")

VGG-19 model from [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) trained on ImageNet.

**Details**

- Model name: `vgg19-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 548.05 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, vgg`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("vgg19-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### wide-resnet101-2-imagenet-torch [Â¶](\#wide-resnet101-2-imagenet-torch "Permalink to this headline")

Wide ResNet-101-2 model from [Wide Residual Networks](https://arxiv.org/abs/1605.07146) trained on ImageNet.

**Details**

- Model name: `wide-resnet101-2-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 242.90 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, wide-resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("wide-resnet101-2-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### wide-resnet50-2-imagenet-torch [Â¶](\#wide-resnet50-2-imagenet-torch "Permalink to this headline")

Wide ResNet-50-2 model from [Wide Residual Networks](https://arxiv.org/abs/1605.07146) trained on ImageNet.

**Details**

- Model name: `wide-resnet50-2-imagenet-torch`

- Model source: [https://pytorch.org/vision/main/models.html](https://pytorch.org/vision/main/models.html)

- Model size: 131.82 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, torch, wide-resnet`


**Requirements**

- Packages: `torch, torchvision`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("wide-resnet50-2-imagenet-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo-nas-torch [Â¶](\#yolo-nas-torch "Permalink to this headline")

YOLO-NAS is an open-source training library for advanced computer vision models. It specializes in accuracy and efficiency, supporting tasks like object detection.

**Details**

- Model name: `yolo-nas-torch`

- Model source: [https://github.com/Deci-AI/super-gradients](https://github.com/Deci-AI/super-gradients)

- Exposes embeddings? no

- Tags: `detection, torch, yolo`


**Requirements**

- Packages: `torch, torchvision, super-gradients`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo-nas-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo11l-coco-torch [Â¶](\#yolo11l-coco-torch "Permalink to this headline")

YOLO11-L model trained on COCO.

**Details**

- Model name: `yolo11l-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov11/](https://docs.ultralytics.com/models/yolov11/)

- Model size: 49.01 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.3.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo11l-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo11l-seg-coco-torch [Â¶](\#yolo11l-seg-coco-torch "Permalink to this headline")

YOLO11-L Segmentation model trained on COCO.

**Details**

- Model name: `yolo11l-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolo11/#\_\_tabbed\_1\_2](https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2)

- Model size: 53.50 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.3.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo11l-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo11m-coco-torch [Â¶](\#yolo11m-coco-torch "Permalink to this headline")

YOLO11-M model trained on COCO.

**Details**

- Model name: `yolo11m-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov11/](https://docs.ultralytics.com/models/yolov11/)

- Model size: 38.80 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.3.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo11m-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo11m-seg-coco-torch [Â¶](\#yolo11m-seg-coco-torch "Permalink to this headline")

YOLO11-M Segmentation model trained on COCO.

**Details**

- Model name: `yolo11m-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolo11/#\_\_tabbed\_1\_2](https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2)

- Model size: 43.30 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.3.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo11m-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo11n-coco-torch [Â¶](\#yolo11n-coco-torch "Permalink to this headline")

YOLO11-N model trained on COCO.

**Details**

- Model name: `yolo11n-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov11/](https://docs.ultralytics.com/models/yolov11/)

- Model size: 5.35 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.3.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo11n-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo11n-seg-coco-torch [Â¶](\#yolo11n-seg-coco-torch "Permalink to this headline")

YOLO11-N Segmentation model trained on COCO.

**Details**

- Model name: `yolo11n-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolo11/#\_\_tabbed\_1\_2](https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2)

- Model size: 5.90 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.3.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo11n-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo11s-coco-torch [Â¶](\#yolo11s-coco-torch "Permalink to this headline")

YOLO11-S model trained on COCO.

**Details**

- Model name: `yolo11s-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov11/](https://docs.ultralytics.com/models/yolov11/)

- Model size: 18.42 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.3.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo11s-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo11s-seg-coco-torch [Â¶](\#yolo11s-seg-coco-torch "Permalink to this headline")

YOLO11-S Segmentation model trained on COCO.

**Details**

- Model name: `yolo11s-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolo11/#\_\_tabbed\_1\_2](https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2)

- Model size: 19.71 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.3.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo11s-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo11x-coco-torch [Â¶](\#yolo11x-coco-torch "Permalink to this headline")

YOLO11-X model trained on COCO.

**Details**

- Model name: `yolo11x-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov11/](https://docs.ultralytics.com/models/yolov11/)

- Model size: 109.33 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.3.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo11x-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo11x-seg-coco-torch [Â¶](\#yolo11x-seg-coco-torch "Permalink to this headline")

YOLO11-X Segmentation model trained on COCO.

**Details**

- Model name: `yolo11x-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolo11/#\_\_tabbed\_1\_2](https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2)

- Model size: 119.30 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.3.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo11x-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov10l-coco-torch [Â¶](\#yolov10l-coco-torch "Permalink to this headline")

YOLOv10-L model trained on COCO.

**Details**

- Model name: `yolov10l-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov10/](https://docs.ultralytics.com/models/yolov10/)

- Model size: 50.00 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.2.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov10l-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov10m-coco-torch [Â¶](\#yolov10m-coco-torch "Permalink to this headline")

YOLOv10-M model trained on COCO.

**Details**

- Model name: `yolov10m-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov10/](https://docs.ultralytics.com/models/yolov10/)

- Model size: 32.09 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.2.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov10m-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov10n-coco-torch [Â¶](\#yolov10n-coco-torch "Permalink to this headline")

YOLOv10-N model trained on COCO.

**Details**

- Model name: `yolov10n-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov10/](https://docs.ultralytics.com/models/yolov10/)

- Model size: 5.59 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.2.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov10n-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov10s-coco-torch [Â¶](\#yolov10s-coco-torch "Permalink to this headline")

YOLOv10-S model trained on COCO.

**Details**

- Model name: `yolov10s-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov10/](https://docs.ultralytics.com/models/yolov10/)

- Model size: 15.85 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.2.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov10s-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov10x-coco-torch [Â¶](\#yolov10x-coco-torch "Permalink to this headline")

YOLOv10-X model trained on COCO.

**Details**

- Model name: `yolov10x-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov10/](https://docs.ultralytics.com/models/yolov10/)

- Model size: 61.41 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.2.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov10x-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov5l-coco-torch [Â¶](\#yolov5l-coco-torch "Permalink to this headline")

Ultralytics YOLOv5l model trained on COCO.

**Details**

- Model name: `yolov5l-coco-torch`

- Model source: [https://pytorch.org/hub/ultralytics\_yolov5](https://pytorch.org/hub/ultralytics_yolov5)

- Model size: 192.88 KB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov5l-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov5m-coco-torch [Â¶](\#yolov5m-coco-torch "Permalink to this headline")

Ultralytics YOLOv5m model trained on COCO.

**Details**

- Model name: `yolov5m-coco-torch`

- Model source: [https://pytorch.org/hub/ultralytics\_yolov5](https://pytorch.org/hub/ultralytics_yolov5)

- Model size: 81.91 KB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov5m-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov5n-coco-torch [Â¶](\#yolov5n-coco-torch "Permalink to this headline")

Ultralytics YOLOv5n model trained on COCO.

**Details**

- Model name: `yolov5n-coco-torch`

- Model source: [https://pytorch.org/hub/ultralytics\_yolov5](https://pytorch.org/hub/ultralytics_yolov5)

- Model size: 7.75 KB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov5n-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov5s-coco-torch [Â¶](\#yolov5s-coco-torch "Permalink to this headline")

Ultralytics YOLOv5s model trained on COCO.

**Details**

- Model name: `yolov5s-coco-torch`

- Model source: [https://pytorch.org/hub/ultralytics\_yolov5](https://pytorch.org/hub/ultralytics_yolov5)

- Model size: 28.25 KB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov5s-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov5x-coco-torch [Â¶](\#yolov5x-coco-torch "Permalink to this headline")

Ultralytics YOLOv5x model trained on COCO.

**Details**

- Model name: `yolov5x-coco-torch`

- Model source: [https://pytorch.org/hub/ultralytics\_yolov5](https://pytorch.org/hub/ultralytics_yolov5)

- Model size: 352.05 KB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov5x-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8l-coco-torch [Â¶](\#yolov8l-coco-torch "Permalink to this headline")

Ultralytics YOLOv8l model trained on COCO.

**Details**

- Model name: `yolov8l-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov8/](https://docs.ultralytics.com/models/yolov8/)

- Model size: 83.70 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8l-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8l-obb-dotav1-torch [Â¶](\#yolov8l-obb-dotav1-torch "Permalink to this headline")

YOLOv8l Oriented Bounding Box model.

**Details**

- Model name: `yolov8l-obb-dotav1-torch`

- Model source: [https://docs.ultralytics.com/tasks/obb/](https://docs.ultralytics.com/tasks/obb/)

- Model size: 85.36 MB

- Exposes embeddings? no

- Tags: `detection, torch, yolo, polylines, obb`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8l-obb-dotav1-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8l-oiv7-torch [Â¶](\#yolov8l-oiv7-torch "Permalink to this headline")

Ultralytics YOLOv8l model trained Open Images v7.

**Details**

- Model name: `yolov8l-oiv7-torch`

- Model source: [https://docs.ultralytics.com/datasets/detect/open-images-v7](https://docs.ultralytics.com/datasets/detect/open-images-v7)

- Model size: 83.70 MB

- Exposes embeddings? no

- Tags: `detection, oiv7, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8l-oiv7-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8l-seg-coco-torch [Â¶](\#yolov8l-seg-coco-torch "Permalink to this headline")

Ultralytics YOLOv8l Segmentation model trained on COCO.

**Details**

- Model name: `yolov8l-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov8/](https://docs.ultralytics.com/models/yolov8/)

- Model size: 88.11 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8l-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8l-world-torch [Â¶](\#yolov8l-world-torch "Permalink to this headline")

YOLOv8l-World model.

**Details**

- Model name: `yolov8l-world-torch`

- Model source: [https://docs.ultralytics.com/models/yolo-world/](https://docs.ultralytics.com/models/yolo-world/)

- Model size: 91.23 MB

- Exposes embeddings? no

- Tags: `detection, torch, yolo, zero-shot`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8l-world-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8m-coco-torch [Â¶](\#yolov8m-coco-torch "Permalink to this headline")

Ultralytics YOLOv8m model trained on COCO.

**Details**

- Model name: `yolov8m-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov8/](https://docs.ultralytics.com/models/yolov8/)

- Model size: 49.70 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8m-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8m-obb-dotav1-torch [Â¶](\#yolov8m-obb-dotav1-torch "Permalink to this headline")

YOLOv8m Oriented Bounding Box model.

**Details**

- Model name: `yolov8m-obb-dotav1-torch`

- Model source: [https://docs.ultralytics.com/tasks/obb/](https://docs.ultralytics.com/tasks/obb/)

- Model size: 50.84 MB

- Exposes embeddings? no

- Tags: `detection, torch, yolo, polylines, obb`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8m-obb-dotav1-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8m-oiv7-torch [Â¶](\#yolov8m-oiv7-torch "Permalink to this headline")

Ultralytics YOLOv8m model trained Open Images v7.

**Details**

- Model name: `yolov8m-oiv7-torch`

- Model source: [https://docs.ultralytics.com/datasets/detect/open-images-v7](https://docs.ultralytics.com/datasets/detect/open-images-v7)

- Model size: 49.70 MB

- Exposes embeddings? no

- Tags: `detection, oiv7, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8m-oiv7-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8m-seg-coco-torch [Â¶](\#yolov8m-seg-coco-torch "Permalink to this headline")

Ultralytics YOLOv8m Segmentation model trained on COCO.

**Details**

- Model name: `yolov8m-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov8/](https://docs.ultralytics.com/models/yolov8/)

- Model size: 52.36 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8m-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8m-world-torch [Â¶](\#yolov8m-world-torch "Permalink to this headline")

YOLOv8m-World model.

**Details**

- Model name: `yolov8m-world-torch`

- Model source: [https://docs.ultralytics.com/models/yolo-world/](https://docs.ultralytics.com/models/yolo-world/)

- Model size: 55.89 MB

- Exposes embeddings? no

- Tags: `detection, torch, yolo, zero-shot`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8m-world-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8n-coco-torch [Â¶](\#yolov8n-coco-torch "Permalink to this headline")

Ultralytics YOLOv8n model trained on COCO.

**Details**

- Model name: `yolov8n-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov8/](https://docs.ultralytics.com/models/yolov8/)

- Model size: 6.23 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8n-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8n-obb-dotav1-torch [Â¶](\#yolov8n-obb-dotav1-torch "Permalink to this headline")

YOLOv8n Oriented Bounding Box model.

**Details**

- Model name: `yolov8n-obb-dotav1-torch`

- Model source: [https://docs.ultralytics.com/tasks/obb/](https://docs.ultralytics.com/tasks/obb/)

- Model size: 6.24 MB

- Exposes embeddings? no

- Tags: `detection, torch, yolo, polylines, obb`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8n-obb-dotav1-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8n-oiv7-torch [Â¶](\#yolov8n-oiv7-torch "Permalink to this headline")

Ultralytics YOLOv8n model trained on Open Images v7.

**Details**

- Model name: `yolov8n-oiv7-torch`

- Model source: [https://docs.ultralytics.com/datasets/detect/open-images-v7](https://docs.ultralytics.com/datasets/detect/open-images-v7)

- Model size: 6.23 MB

- Exposes embeddings? no

- Tags: `detection, oiv7, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8n-oiv7-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8n-seg-coco-torch [Â¶](\#yolov8n-seg-coco-torch "Permalink to this headline")

Ultralytics YOLOv8n Segmentation model trained on COCO.

**Details**

- Model name: `yolov8n-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov8/](https://docs.ultralytics.com/models/yolov8/)

- Model size: 6.73 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8n-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8s-coco-torch [Â¶](\#yolov8s-coco-torch "Permalink to this headline")

Ultralytics YOLOv8s model trained on COCO.

**Details**

- Model name: `yolov8s-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov8/](https://docs.ultralytics.com/models/yolov8/)

- Model size: 21.53 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8s-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8s-obb-dotav1-torch [Â¶](\#yolov8s-obb-dotav1-torch "Permalink to this headline")

YOLOv8s Oriented Bounding Box model.

**Details**

- Model name: `yolov8s-obb-dotav1-torch`

- Model source: [https://docs.ultralytics.com/tasks/obb/](https://docs.ultralytics.com/tasks/obb/)

- Model size: 22.17 MB

- Exposes embeddings? no

- Tags: `detection, torch, yolo, polylines, obb`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8s-obb-dotav1-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8s-oiv7-torch [Â¶](\#yolov8s-oiv7-torch "Permalink to this headline")

Ultralytics YOLOv8s model trained on Open Images v7.

**Details**

- Model name: `yolov8s-oiv7-torch`

- Model source: [https://docs.ultralytics.com/datasets/detect/open-images-v7](https://docs.ultralytics.com/datasets/detect/open-images-v7)

- Model size: 21.53 MB

- Exposes embeddings? no

- Tags: `detection, oiv7, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8s-oiv7-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8s-seg-coco-torch [Â¶](\#yolov8s-seg-coco-torch "Permalink to this headline")

Ultralytics YOLOv8s Segmentation model trained on COCO.

**Details**

- Model name: `yolov8s-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov8/](https://docs.ultralytics.com/models/yolov8/)

- Model size: 22.79 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8s-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8s-world-torch [Â¶](\#yolov8s-world-torch "Permalink to this headline")

YOLOv8s-World model.

**Details**

- Model name: `yolov8s-world-torch`

- Model source: [https://docs.ultralytics.com/models/yolo-world/](https://docs.ultralytics.com/models/yolo-world/)

- Model size: 25.91 MB

- Exposes embeddings? no

- Tags: `detection, torch, yolo, zero-shot`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8s-world-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8x-coco-torch [Â¶](\#yolov8x-coco-torch "Permalink to this headline")

Ultralytics YOLOv8x model trained on COCO.

**Details**

- Model name: `yolov8x-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov8/](https://docs.ultralytics.com/models/yolov8/)

- Model size: 130.53 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8x-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8x-obb-dotav1-torch [Â¶](\#yolov8x-obb-dotav1-torch "Permalink to this headline")

YOLOv8x Oriented Bounding Box model.

**Details**

- Model name: `yolov8x-obb-dotav1-torch`

- Model source: [https://docs.ultralytics.com/tasks/obb/](https://docs.ultralytics.com/tasks/obb/)

- Model size: 133.07 MB

- Exposes embeddings? no

- Tags: `detection, torch, yolo, polylines, obb`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8x-obb-dotav1-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8x-oiv7-torch [Â¶](\#yolov8x-oiv7-torch "Permalink to this headline")

Ultralytics YOLOv8x model trained Open Images v7.

**Details**

- Model name: `yolov8x-oiv7-torch`

- Model source: [https://docs.ultralytics.com/datasets/detect/open-images-v7](https://docs.ultralytics.com/datasets/detect/open-images-v7)

- Model size: 130.53 MB

- Exposes embeddings? no

- Tags: `detection, oiv7, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8x-oiv7-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8x-seg-coco-torch [Â¶](\#yolov8x-seg-coco-torch "Permalink to this headline")

Ultralytics YOLOv8x Segmentation model trained on COCO.

**Details**

- Model name: `yolov8x-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov8/](https://docs.ultralytics.com/models/yolov8/)

- Model size: 137.40 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8x-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov8x-world-torch [Â¶](\#yolov8x-world-torch "Permalink to this headline")

YOLOv8x-World model.

**Details**

- Model name: `yolov8x-world-torch`

- Model source: [https://docs.ultralytics.com/models/yolo-world/](https://docs.ultralytics.com/models/yolo-world/)

- Model size: 141.11 MB

- Exposes embeddings? no

- Tags: `detection, torch, yolo, zero-shot`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov8x-world-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov9c-coco-torch [Â¶](\#yolov9c-coco-torch "Permalink to this headline")

YOLOv9-C model trained on COCO.

**Details**

- Model name: `yolov9c-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov9/](https://docs.ultralytics.com/models/yolov9/)

- Model size: 49.40 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov9c-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov9c-seg-coco-torch [Â¶](\#yolov9c-seg-coco-torch "Permalink to this headline")

YOLOv9-C Segmentation model trained on COCO.

**Details**

- Model name: `yolov9c-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov9/#\_\_tabbed\_1\_2](https://docs.ultralytics.com/models/yolov9/#__tabbed_1_2)

- Model size: 107.20 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.42`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov9c-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov9e-coco-torch [Â¶](\#yolov9e-coco-torch "Permalink to this headline")

YOLOv9-E model trained on COCO.

**Details**

- Model name: `yolov9e-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov9/](https://docs.ultralytics.com/models/yolov9/)

- Model size: 112.09 MB

- Exposes embeddings? no

- Tags: `detection, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.0`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov9e-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolov9e-seg-coco-torch [Â¶](\#yolov9e-seg-coco-torch "Permalink to this headline")

YOLOv9-E Segmentation model trained on COCO.

**Details**

- Model name: `yolov9e-seg-coco-torch`

- Model source: [https://docs.ultralytics.com/models/yolov9/#\_\_tabbed\_1\_2](https://docs.ultralytics.com/models/yolov9/#__tabbed_1_2)

- Model size: 232.20 MB

- Exposes embeddings? no

- Tags: `segmentation, coco, torch, yolo`


**Requirements**

- Packages: `torch>=1.7.0, torchvision>=0.8.1, ultralytics>=8.1.42`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolov9e-seg-coco-torch")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### zero-shot-classification-transformer-torch [Â¶](\#zero-shot-classification-transformer-torch "Permalink to this headline")

Hugging Face Transformers model for zero-shot image classification.

**Details**

- Model name: `zero-shot-classification-transformer-torch`

- Model source: [https://huggingface.co/docs/transformers/tasks/zero\_shot\_image\_classification](https://huggingface.co/docs/transformers/tasks/zero_shot_image_classification)

- Exposes embeddings? yes

- Tags: `classification, logits, embeddings, torch, transformers, zero-shot`


**Requirements**

- Packages: `torch, torchvision, transformers`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model(
    "zero-shot-classification-transformer-torch",
    classes=["person", "dog", "cat", "bird", "car", "tree", "chair"],
)

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### zero-shot-detection-transformer-torch [Â¶](\#zero-shot-detection-transformer-torch "Permalink to this headline")

Hugging Face Transformers model for zero-shot object detection.

**Details**

- Model name: `zero-shot-detection-transformer-torch`

- Model source: [https://huggingface.co/docs/transformers/tasks/zero\_shot\_object\_detection](https://huggingface.co/docs/transformers/tasks/zero_shot_object_detection)

- Exposes embeddings? yes

- Tags: `detection, logits, embeddings, torch, transformers, zero-shot`


**Requirements**

- Packages: `torch, torchvision, transformers`

- CPU support

  - yes
- GPU support

  - yes

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model(
    "zero-shot-detection-transformer-torch",
    classes=["person", "dog", "cat", "bird", "car", "tree", "chair"],
)

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

## TensorFlow models [Â¶](\#tensorflow-models "Permalink to this headline")

### centernet-hg104-1024-coco-tf2 [Â¶](\#centernet-hg104-1024-coco-tf2 "Permalink to this headline")

CenterNet model from [Objects as Points](https://arxiv.org/abs/1904.07850) with the Hourglass-104 backbone trained on COCO resized to 1024x1024.

**Details**

- Model name: `centernet-hg104-1024-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 1.33 GB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, centernet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("centernet-hg104-1024-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### centernet-hg104-512-coco-tf2 [Â¶](\#centernet-hg104-512-coco-tf2 "Permalink to this headline")

CenterNet model from [Objects as Points](https://arxiv.org/abs/1904.07850) with the Hourglass-104 backbone trained on COCO resized to 512x512.

**Details**

- Model name: `centernet-hg104-512-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 1.49 GB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, centernet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("centernet-hg104-512-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### centernet-mobilenet-v2-fpn-512-coco-tf2 [Â¶](\#centernet-mobilenet-v2-fpn-512-coco-tf2 "Permalink to this headline")

CenterNet model from [Objects as Points](https://arxiv.org/abs/1904.07850) with the MobileNetV2 backbone trained on COCO resized to 512x512.

**Details**

- Model name: `centernet-mobilenet-v2-fpn-512-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 41.98 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, centernet, mobilenet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("centernet-mobilenet-v2-fpn-512-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### centernet-resnet101-v1-fpn-512-coco-tf2 [Â¶](\#centernet-resnet101-v1-fpn-512-coco-tf2 "Permalink to this headline")

CenterNet model from [Objects as Points](https://arxiv.org/abs/1904.07850) with the ResNet-101v1 backbone + FPN trained on COCO resized to 512x512.

**Details**

- Model name: `centernet-resnet101-v1-fpn-512-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 329.96 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, centernet, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("centernet-resnet101-v1-fpn-512-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### centernet-resnet50-v1-fpn-512-coco-tf2 [Â¶](\#centernet-resnet50-v1-fpn-512-coco-tf2 "Permalink to this headline")

CenterNet model from [Objects as Points](https://arxiv.org/abs/1904.07850) with the ResNet-50-v1 backbone + FPN trained on COCO resized to 512x512.

**Details**

- Model name: `centernet-resnet50-v1-fpn-512-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 194.61 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, centernet, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("centernet-resnet50-v1-fpn-512-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### centernet-resnet50-v2-512-coco-tf2 [Â¶](\#centernet-resnet50-v2-512-coco-tf2 "Permalink to this headline")

CenterNet model from [Objects as Points](https://arxiv.org/abs/1904.07850) with the ResNet-50v2 backbone trained on COCO resized to 512x512.

**Details**

- Model name: `centernet-resnet50-v2-512-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 226.95 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, centernet, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("centernet-resnet50-v2-512-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### deeplabv3-cityscapes-tf [Â¶](\#deeplabv3-cityscapes-tf "Permalink to this headline")

DeepLabv3+ semantic segmentation model from [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1802.02611) with Xception backbone trained on the Cityscapes dataset.

**Details**

- Model name: `deeplabv3-cityscapes-tf`

- Model source: [https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model\_zoo.md](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md)

- Model size: 158.04 MB

- Exposes embeddings? no

- Tags: `segmentation, cityscapes, tf, deeplabv3`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("deeplabv3-cityscapes-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### deeplabv3-mnv2-cityscapes-tf [Â¶](\#deeplabv3-mnv2-cityscapes-tf "Permalink to this headline")

DeepLabv3+ semantic segmentation model from [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1802.02611) with MobileNetV2 backbone trained on the Cityscapes dataset.

**Details**

- Model name: `deeplabv3-mnv2-cityscapes-tf`

- Model source: [https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model\_zoo.md](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md)

- Model size: 8.37 MB

- Exposes embeddings? no

- Tags: `segmentation, cityscapes, tf, deeplabv3`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("deeplabv3-mnv2-cityscapes-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d0-512-coco-tf2 [Â¶](\#efficientdet-d0-512-coco-tf2 "Permalink to this headline")

EfficientDet-D0 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO resized to 512x512.

**Details**

- Model name: `efficientdet-d0-512-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 29.31 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d0-512-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d0-coco-tf1 [Â¶](\#efficientdet-d0-coco-tf1 "Permalink to this headline")

EfficientDet-D0 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO.

**Details**

- Model name: `efficientdet-d0-coco-tf1`

- Model source: [https://github.com/voxel51/automl/tree/master/efficientdet](https://github.com/voxel51/automl/tree/master/efficientdet)

- Model size: 38.20 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf1, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=1.14,<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=1.14,<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d0-coco-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d1-640-coco-tf2 [Â¶](\#efficientdet-d1-640-coco-tf2 "Permalink to this headline")

EfficientDet-D1 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO resized to 640x640.

**Details**

- Model name: `efficientdet-d1-640-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 49.44 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d1-640-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d1-coco-tf1 [Â¶](\#efficientdet-d1-coco-tf1 "Permalink to this headline")

EfficientDet-D1 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO.

**Details**

- Model name: `efficientdet-d1-coco-tf1`

- Model source: [https://github.com/voxel51/automl/tree/master/efficientdet](https://github.com/voxel51/automl/tree/master/efficientdet)

- Model size: 61.64 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf1, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=1.14,<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=1.14,<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d1-coco-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d2-768-coco-tf2 [Â¶](\#efficientdet-d2-768-coco-tf2 "Permalink to this headline")

EfficientDet-D2 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO resized to 768x768.

**Details**

- Model name: `efficientdet-d2-768-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 60.01 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d2-768-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d2-coco-tf1 [Â¶](\#efficientdet-d2-coco-tf1 "Permalink to this headline")

EfficientDet-D2 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO.

**Details**

- Model name: `efficientdet-d2-coco-tf1`

- Model source: [https://github.com/voxel51/automl/tree/master/efficientdet](https://github.com/voxel51/automl/tree/master/efficientdet)

- Model size: 74.00 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf1, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=1.14,<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=1.14,<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d2-coco-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d3-896-coco-tf2 [Â¶](\#efficientdet-d3-896-coco-tf2 "Permalink to this headline")

EfficientDet-D3 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO resized to 896x896.

**Details**

- Model name: `efficientdet-d3-896-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 88.56 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d3-896-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d3-coco-tf1 [Â¶](\#efficientdet-d3-coco-tf1 "Permalink to this headline")

EfficientDet-D3 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO.

**Details**

- Model name: `efficientdet-d3-coco-tf1`

- Model source: [https://github.com/voxel51/automl/tree/master/efficientdet](https://github.com/voxel51/automl/tree/master/efficientdet)

- Model size: 106.44 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf1, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=1.14,<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=1.14,<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d3-coco-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d4-1024-coco-tf2 [Â¶](\#efficientdet-d4-1024-coco-tf2 "Permalink to this headline")

EfficientDet-D4 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO resized to 1024x1024.

**Details**

- Model name: `efficientdet-d4-1024-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 151.15 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d4-1024-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d4-coco-tf1 [Â¶](\#efficientdet-d4-coco-tf1 "Permalink to this headline")

EfficientDet-D4 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO.

**Details**

- Model name: `efficientdet-d4-coco-tf1`

- Model source: [https://github.com/voxel51/automl/tree/master/efficientdet](https://github.com/voxel51/automl/tree/master/efficientdet)

- Model size: 175.33 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf1, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=1.14,<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=1.14,<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d4-coco-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d5-1280-coco-tf2 [Â¶](\#efficientdet-d5-1280-coco-tf2 "Permalink to this headline")

EfficientDet-D5 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO resized to 1280x1280.

**Details**

- Model name: `efficientdet-d5-1280-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 244.41 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d5-1280-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d5-coco-tf1 [Â¶](\#efficientdet-d5-coco-tf1 "Permalink to this headline")

EfficientDet-D5 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO.

**Details**

- Model name: `efficientdet-d5-coco-tf1`

- Model source: [https://github.com/voxel51/automl/tree/master/efficientdet](https://github.com/voxel51/automl/tree/master/efficientdet)

- Model size: 275.81 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf1, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=1.14,<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=1.14,<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d5-coco-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d6-1280-coco-tf2 [Â¶](\#efficientdet-d6-1280-coco-tf2 "Permalink to this headline")

EfficientDet-D6 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO resized to 1280x1280.

**Details**

- Model name: `efficientdet-d6-1280-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 375.63 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d6-1280-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d6-coco-tf1 [Â¶](\#efficientdet-d6-coco-tf1 "Permalink to this headline")

EfficientDet-D6 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO.

**Details**

- Model name: `efficientdet-d6-coco-tf1`

- Model source: [https://github.com/voxel51/automl/tree/master/efficientdet](https://github.com/voxel51/automl/tree/master/efficientdet)

- Model size: 416.43 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf1, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=1.14,<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=1.14,<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d6-coco-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### efficientdet-d7-1536-coco-tf2 [Â¶](\#efficientdet-d7-1536-coco-tf2 "Permalink to this headline")

EfficientDet-D7 model from [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) trained on COCO resized to 1536x1536.

**Details**

- Model name: `efficientdet-d7-1536-coco-tf2`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 376.20 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, efficientdet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("efficientdet-d7-1536-coco-tf2")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### faster-rcnn-inception-resnet-atrous-v2-coco-tf [Â¶](\#faster-rcnn-inception-resnet-atrous-v2-coco-tf "Permalink to this headline")

Faster R-CNN model from [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) atrous version with Inception backbone trained on COCO.

**Details**

- Model name: `faster-rcnn-inception-resnet-atrous-v2-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 234.46 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, faster-rcnn, inception, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("faster-rcnn-inception-resnet-atrous-v2-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf [Â¶](\#faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf "Permalink to this headline")

Faster R-CNN model from [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) atrous version with low-proposals and Inception backbone trained on COCO.

**Details**

- Model name: `faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 234.46 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, faster-rcnn, inception, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### faster-rcnn-inception-v2-coco-tf [Â¶](\#faster-rcnn-inception-v2-coco-tf "Permalink to this headline")

Faster R-CNN model from [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) with Inception v2 backbone trained on COCO.

**Details**

- Model name: `faster-rcnn-inception-v2-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 52.97 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, faster-rcnn, inception`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("faster-rcnn-inception-v2-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### faster-rcnn-nas-coco-tf [Â¶](\#faster-rcnn-nas-coco-tf "Permalink to this headline")

Faster R-CNN model from [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) with NAS-net backbone trained on COCO.

**Details**

- Model name: `faster-rcnn-nas-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 404.95 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, faster-rcnn`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("faster-rcnn-nas-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### faster-rcnn-nas-lowproposals-coco-tf [Â¶](\#faster-rcnn-nas-lowproposals-coco-tf "Permalink to this headline")

Faster R-CNN model from [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) with low-proposals and NAS-net backbone trained on COCO.

**Details**

- Model name: `faster-rcnn-nas-lowproposals-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 404.88 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, faster-rcnn`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("faster-rcnn-nas-lowproposals-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### faster-rcnn-resnet101-coco-tf [Â¶](\#faster-rcnn-resnet101-coco-tf "Permalink to this headline")

Faster R-CNN model from [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) with ResNet-101 backbone trained on COCO.

**Details**

- Model name: `faster-rcnn-resnet101-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 186.41 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, faster-rcnn, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("faster-rcnn-resnet101-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### faster-rcnn-resnet101-lowproposals-coco-tf [Â¶](\#faster-rcnn-resnet101-lowproposals-coco-tf "Permalink to this headline")

Faster R-CNN model from [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) with low-proposals and ResNet-101 backbone trained on COCO.

**Details**

- Model name: `faster-rcnn-resnet101-lowproposals-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 186.41 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, faster-rcnn, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("faster-rcnn-resnet101-lowproposals-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### faster-rcnn-resnet50-coco-tf [Â¶](\#faster-rcnn-resnet50-coco-tf "Permalink to this headline")

Faster R-CNN model from [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) with ResNet-50 backbone trained on COCO.

**Details**

- Model name: `faster-rcnn-resnet50-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 113.57 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, faster-rcnn, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("faster-rcnn-resnet50-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### faster-rcnn-resnet50-lowproposals-coco-tf [Â¶](\#faster-rcnn-resnet50-lowproposals-coco-tf "Permalink to this headline")

Faster R-CNN model from [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) with low-proposals and ResNet-50 backbone trained on COCO.

**Details**

- Model name: `faster-rcnn-resnet50-lowproposals-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 113.57 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, faster-rcnn, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("faster-rcnn-resnet50-lowproposals-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### inception-resnet-v2-imagenet-tf1 [Â¶](\#inception-resnet-v2-imagenet-tf1 "Permalink to this headline")

Inception v2 model from [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567) trained on ImageNet.

**Details**

- Model name: `inception-resnet-v2-imagenet-tf1`

- Model source: [https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models](https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models)

- Model size: 213.81 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, tf1, inception, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("inception-resnet-v2-imagenet-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### inception-v4-imagenet-tf1 [Â¶](\#inception-v4-imagenet-tf1 "Permalink to this headline")

Inception v4 model from [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261) trained on ImageNet.

**Details**

- Model name: `inception-v4-imagenet-tf1`

- Model source: [https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models](https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models)

- Model size: 163.31 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, tf1, inception`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("inception-v4-imagenet-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### mask-rcnn-inception-resnet-v2-atrous-coco-tf [Â¶](\#mask-rcnn-inception-resnet-v2-atrous-coco-tf "Permalink to this headline")

Mask R-CNN model from [Mask R-CNN](https://arxiv.org/abs/1703.06870) atrous version with Inception backbone trained on COCO.

**Details**

- Model name: `mask-rcnn-inception-resnet-v2-atrous-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 254.51 MB

- Exposes embeddings? no

- Tags: `instances, coco, tf, mask-rcnn, inception, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("mask-rcnn-inception-resnet-v2-atrous-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### mask-rcnn-inception-v2-coco-tf [Â¶](\#mask-rcnn-inception-v2-coco-tf "Permalink to this headline")

Mask R-CNN model from [Mask R-CNN](https://arxiv.org/abs/1703.06870) with Inception backbone trained on COCO.

**Details**

- Model name: `mask-rcnn-inception-v2-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 64.03 MB

- Exposes embeddings? no

- Tags: `instances, coco, tf, mask-rcnn, inception`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("mask-rcnn-inception-v2-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### mask-rcnn-resnet101-atrous-coco-tf [Â¶](\#mask-rcnn-resnet101-atrous-coco-tf "Permalink to this headline")

Mask R-CNN model from [Mask R-CNN](https://arxiv.org/abs/1703.06870) atrous version with ResNet-101 backbone trained on COCO.

**Details**

- Model name: `mask-rcnn-resnet101-atrous-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 211.56 MB

- Exposes embeddings? no

- Tags: `instances, coco, tf, mask-rcnn, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("mask-rcnn-resnet101-atrous-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### mask-rcnn-resnet50-atrous-coco-tf [Â¶](\#mask-rcnn-resnet50-atrous-coco-tf "Permalink to this headline")

Mask R-CNN model from [Mask R-CNN](https://arxiv.org/abs/1703.06870) atrous version with ResNet-50 backbone trained on COCO.

**Details**

- Model name: `mask-rcnn-resnet50-atrous-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 138.29 MB

- Exposes embeddings? no

- Tags: `instances, coco, tf, mask-rcnn, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("mask-rcnn-resnet50-atrous-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### mobilenet-v2-imagenet-tf1 [Â¶](\#mobilenet-v2-imagenet-tf1 "Permalink to this headline")

MobileNetV2 model from [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381) trained on ImageNet.

**Details**

- Model name: `mobilenet-v2-imagenet-tf1`

- Model source: None

- Model size: 13.64 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, tf1, mobilenet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("mobilenet-v2-imagenet-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### resnet-v1-50-imagenet-tf1 [Â¶](\#resnet-v1-50-imagenet-tf1 "Permalink to this headline")

ResNet-50 v1 model from [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) trained on ImageNet.

**Details**

- Model name: `resnet-v1-50-imagenet-tf1`

- Model source: [https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models](https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models)

- Model size: 97.84 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, tf1, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("resnet-v1-50-imagenet-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### resnet-v2-50-imagenet-tf1 [Â¶](\#resnet-v2-50-imagenet-tf1 "Permalink to this headline")

ResNet-50 v2 model from [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) trained on ImageNet.

**Details**

- Model name: `resnet-v2-50-imagenet-tf1`

- Model source: [https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models](https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models)

- Model size: 97.86 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, tf1, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("resnet-v2-50-imagenet-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### rfcn-resnet101-coco-tf [Â¶](\#rfcn-resnet101-coco-tf "Permalink to this headline")

R-FCN object detection model from [R-FCN: Object Detection via Region-based Fully Convolutional Networks](https://arxiv.org/abs/1605.06409) with ResNet-101 backbone trained on COCO.

**Details**

- Model name: `rfcn-resnet101-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 208.16 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, rfcn, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("rfcn-resnet101-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### ssd-inception-v2-coco-tf [Â¶](\#ssd-inception-v2-coco-tf "Permalink to this headline")

Inception Single Shot Detector model from [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) trained on COCO.

**Details**

- Model name: `ssd-inception-v2-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 97.50 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, ssd, inception`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("ssd-inception-v2-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### ssd-mobilenet-v1-coco-tf [Â¶](\#ssd-mobilenet-v1-coco-tf "Permalink to this headline")

Single Shot Detector model from [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) with MobileNetV1 backbone trained on COCO.

**Details**

- Model name: `ssd-mobilenet-v1-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 27.83 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, ssd, mobilenet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("ssd-mobilenet-v1-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### ssd-mobilenet-v1-fpn-640-coco17 [Â¶](\#ssd-mobilenet-v1-fpn-640-coco17 "Permalink to this headline")

MobileNetV1 model from [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/pdf/1801.04381.pdf) resized to 640x640.

**Details**

- Model name: `ssd-mobilenet-v1-fpn-640-coco17`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 43.91 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, ssd, mobilenet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("ssd-mobilenet-v1-fpn-640-coco17")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### ssd-mobilenet-v1-fpn-coco-tf [Â¶](\#ssd-mobilenet-v1-fpn-coco-tf "Permalink to this headline")

FPN Single Shot Detector model from [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) with MobileNetV1 backbone trained on COCO.

**Details**

- Model name: `ssd-mobilenet-v1-fpn-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 48.97 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, ssd, mobilenet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("ssd-mobilenet-v1-fpn-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### ssd-mobilenet-v2-320-coco17 [Â¶](\#ssd-mobilenet-v2-320-coco17 "Permalink to this headline")

MobileNetV2 model from [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/pdf/1801.04381.pdf) resized to 320x320.

**Details**

- Model name: `ssd-mobilenet-v2-320-coco17`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf2\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md)

- Model size: 43.91 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf2, ssd, mobilenet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow>=2|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu>=2|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("ssd-mobilenet-v2-320-coco17")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### ssd-resnet50-fpn-coco-tf [Â¶](\#ssd-resnet50-fpn-coco-tf "Permalink to this headline")

FPN Single Shot Detector model from [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) with ResNet-50 backbone trained on COCO.

**Details**

- Model name: `ssd-resnet50-fpn-coco-tf`

- Model source: [https://github.com/tensorflow/models/blob/archive/research/object\_detection/g3doc/tf1\_detection\_zoo.md](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)

- Model size: 128.07 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf, ssd, resnet`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow|tensorflow-macos`
- GPU support

  - yes

  - Packages: `tensorflow-gpu|tensorflow>=2|tensorflow-macos`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("ssd-resnet50-fpn-coco-tf")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### vgg16-imagenet-tf1 [Â¶](\#vgg16-imagenet-tf1 "Permalink to this headline")

VGG-16 model from [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) trained on ImageNet.

**Details**

- Model name: `vgg16-imagenet-tf1`

- Model source: [https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md](https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md)

- Model size: 527.80 MB

- Exposes embeddings? yes

- Tags: `classification, embeddings, logits, imagenet, tf1, vgg`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "imagenet-sample",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("vgg16-imagenet-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

### yolo-v2-coco-tf1 [Â¶](\#yolo-v2-coco-tf1 "Permalink to this headline")

YOLOv2 model from [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) trained on COCO.

**Details**

- Model name: `yolo-v2-coco-tf1`

- Model source: [https://github.com/thtrieu/darkflow](https://github.com/thtrieu/darkflow)

- Model size: 194.49 MB

- Exposes embeddings? no

- Tags: `detection, coco, tf1, yolo`


**Requirements**

- CPU support

  - yes

  - Packages: `tensorflow<2`
- GPU support

  - yes

  - Packages: `tensorflow-gpu<2`

**Example usage**

```python
import fiftyone as fo
import fiftyone.zoo as foz

dataset = foz.load_zoo_dataset(
    "coco-2017",
    split="validation",
    dataset_name=fo.get_default_dataset_name(),
    max_samples=50,
    shuffle=True,
)

model = foz.load_zoo_model("yolo-v2-coco-tf1")

dataset.apply_model(model, label_field="predictions")

session = fo.launch_app(dataset)

```

